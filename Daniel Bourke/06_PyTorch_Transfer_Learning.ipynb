{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 06. PyTorch Transfer Learning\n",
        "Taking the parameters of what one model has learned on another dataset and applying it on our own problem...\n",
        "\n",
        "Pretrained models are also called as foundation models."
      ],
      "metadata": {
        "id": "47G5VUCKVwSu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UrL0QUrVrs1",
        "outputId": "eaf89beb-2aad-48cd-a63d-7c1d2618fff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121\n",
            "0.17.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)  # want 0.13+"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "    from going_modular.going_modular import data_setup, engine\n",
        "except:\n",
        "    # Get the going_modular scripts\n",
        "    print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "    !git clone https://github.com/mrdbourke/pytorch-deep-learning\n",
        "    !mv pytorch-deep-learning/going_modular .\n",
        "    !rm -rf pytorch-deep-learning\n",
        "    from going_modular.going_modular import data_setup, engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3l6pdBWFWT6Q",
        "outputId": "18190ef4-0176-4b7e-b4d4-54648634c8e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\n",
            "Cloning into 'pytorch-deep-learning'...\n",
            "remote: Enumerating objects: 4056, done.\u001b[K\n",
            "remote: Total 4056 (delta 0), reused 0 (delta 0), pack-reused 4056\u001b[K\n",
            "Receiving objects: 100% (4056/4056), 646.90 MiB | 23.50 MiB/s, done.\n",
            "Resolving deltas: 100% (2371/2371), done.\n",
            "Updating files: 100% (248/248), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8JyJS4AJXMSS",
        "outputId": "95595d51-cf66-4aea-a57f-7a5a4b1db16a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get Data\n",
        "We need our pizza, sushi and steak data to build a transfer model on."
      ],
      "metadata": {
        "id": "YqMRfDn0X1t6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import requests\n",
        "\n",
        "# Setup data path and image path\n",
        "data_path = Path('data/')\n",
        "image_path = data_path / 'pizza_steak_sushi'  # Images from a subset of classes from the Food101 dataset.\n",
        "\n",
        "# If the image folder doesn't exist, download it and create folder...\n",
        "if image_path.is_dir():\n",
        "  print(f'{image_path} directory exists, skipping re-download...')\n",
        "else:\n",
        "  print(f'Did not find {image_path}, downloading it...')\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # Downloading the data\n",
        "  with open(data_path/'pizza_steak_sushi.zip', 'wb') as f:\n",
        "    request = requests.get('https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip')\n",
        "    print('Downloading pizza, steak, sushi data...')\n",
        "    f.write(request.content)\n",
        "\n",
        "  # Unzip the data\n",
        "  with zipfile.ZipFile(data_path / 'pizza_steak_sushi.zip', 'r') as zip_ref:\n",
        "    print('Unzipping pizza, steak and sushi data')\n",
        "    zip_ref.extract_all(image_path)\n",
        "\n",
        "  # Deleting the zip file\n",
        "  os.remove(data_path/'pizza_steak_sushi.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BYTOBDNXxMa",
        "outputId": "5e32a994-2a3d-4f22-a038-993851522881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi directory exists, skipping re-download...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = image_path / 'train'\n",
        "test_dir = image_path / 'test'\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qbr48mTiYJMW",
        "outputId": "135105ba-b3cd-4a29-85bf-57868d6d402f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PosixPath('data/pizza_steak_sushi/train'),\n",
              " PosixPath('data/pizza_steak_sushi/test'))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create Datasets and DataLoaders\n",
        "\n",
        "We'll use the `data_setup.py` module we created earlier in the course. The `create_dataloaders()` function will help us create these.\n",
        "\n",
        "For transforming the data, `torchvision` 0.13+ has two ways:\n",
        "1. Manually created transforms - You define what transforms you want your data to go through\n",
        "2. Automatically created transforms - the transforms for your data are automatically defined by the model you use.\n",
        "\n",
        "NOTE: When using a pretrained model, it's important that the data (including your own custom data) is transformed in the same way as the data the model was trained on."
      ],
      "metadata": {
        "id": "XUQsAowZay_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Creating a transform for `torchvision.models` (manual creation)\n",
        "\n",
        "`torchvision.models` contains pretrained models (models ready for transfer learning) right within torchvision.\n",
        "\n",
        "> All pre-trained models expect input images normalized in the same way i.e. mini-batches of 3-channel RGB images of shape (3xWxH), where W and H are expected to be atleast 224. The images must be loaded into a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]. You can use the following transform to normalize."
      ],
      "metadata": {
        "id": "4O1nchrwclA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# The mean and std values are the values for the imagenet dataset's distribution.\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Reshape images to 224, 224\n",
        "    transforms.ToTensor(),  # Get images into range [0, 1]\n",
        "    normalize\n",
        "])"
      ],
      "metadata": {
        "id": "D0Xoe8MZcxT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular.going_modular import data_setup\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir,\n",
        "                                                                               test_dir,\n",
        "                                                                               manual_transforms,\n",
        "                                                                               batch_size=32,\n",
        "                                                                               num_workers=os.cpu_count())\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQHiAvG_fNlR",
        "outputId": "65a10e14-6ba1-4479-b5dd-f8c23e317ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7bc472feea10>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7bc47dfcd0c0>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Creating a transform for `torchvision.models` (auto-creation)\n",
        "\n",
        "As of `torchvision` 0.13+ there is now support for automatic data transform creation based on the pretrained model weights that you're using."
      ],
      "metadata": {
        "id": "XIURHKQdfraX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a set of pretrained model weights\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT  # \"DEFAULT\" = best available weights\n",
        "weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-1qT6Wkfie0",
        "outputId": "2defb7c5-a42c-48f2-a02b-698b49504cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet_B0_Weights.IMAGENET1K_V1"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the transforms used to create our pretrained weights\n",
        "auto_transforms = weights.transforms()\n",
        "auto_transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9_y19hHhFZ7",
        "outputId": "d6bda9a8-c2e8-49f0-d615-d023800fe898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassification(\n",
              "    crop_size=[224]\n",
              "    resize_size=[256]\n",
              "    mean=[0.485, 0.456, 0.406]\n",
              "    std=[0.229, 0.224, 0.225]\n",
              "    interpolation=InterpolationMode.BICUBIC\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloaders from automatic transforms\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir,\n",
        "                                                                               test_dir,\n",
        "                                                                               auto_transforms,\n",
        "                                                                               batch_size=32,\n",
        "                                                                               num_workers=os.cpu_count())\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYONagefhN3t",
        "outputId": "244d2e9b-77e0-4f42-a528-950fa3178d14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7bc472f75450>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7bc472f77a30>,\n",
              " ['pizza', 'steak', 'sushi'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EkkXkebqhbWW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}