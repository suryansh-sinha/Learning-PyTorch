{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 00. PyTorch Fundamentals"
      ],
      "metadata": {
        "id": "GUyxALIF5uOf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om1uDyiD0tpo"
      },
      "source": [
        "This is also a notebook covering the fundamentals of PyTorch. I learned all this from Daniel Bourke's Learn PyTorch in a day (literally) video on youtube.\n",
        "This is chapter 00 from the tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRALpnLgkAyj",
        "outputId": "005ebd18-5662-48ba-ab29-6d59f2cf755d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Aug 24 18:50:48 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi # Tells us what GPU our machine is using ^_^ ðŸ«¡."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG6FjIpBkP4a",
        "outputId": "25d576af-c142-4c8f-d5ed-3e4b896af99e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dcUCU5Zku3h",
        "outputId": "7cea1e93-d7e3-4744-9f80-db54227a92f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm excited to learn PyTorch\n"
          ]
        }
      ],
      "source": [
        "print('Hello! I\\'m excited to learn PyTorch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5gvz6y4mixn"
      },
      "source": [
        "## Introduction to Tensors\n",
        "\n",
        "A tensor, according to PyTorch is a n-dimensioned matrix that contains data of similar datatype.\n",
        "\n",
        "### Creating Tensors\n",
        "\n",
        "PyTorch tensors are created using torch.tensor()\n",
        "Assignment: Read through torch.Tensor documentation for 10 mins atleast.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9aiRvB8mmbf",
        "outputId": "97d50e42-f70f-46db-e90b-553d41995095"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3Ugq-AZm4wy",
        "outputId": "0747bb8d-247e-4590-bacb-5525aa9479c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "scalar.ndim # Gives us the number of dimensions in our tensor.\n",
        "# A scalar has 0 dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVfbTu7KoMFs",
        "outputId": "99ece7bd-233e-481d-f618-6c5ddf2f1796"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Get scalar back as a python int.\n",
        "scalar.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iteyqK4n4hm",
        "outputId": "321b900c-2035-48d5-f93d-04c792f1dcb9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# vector\n",
        "vector = torch.tensor([7,7])\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65gPgbcNoiU2",
        "outputId": "fb9f6b4c-73cb-4085-938b-0a768530cc27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "vector.ndim # You can assume that the dimension is the number of indices required to reference value in the tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5bcymeWolv4",
        "outputId": "a2f9d226-7fa4-4810-bfc7-f1c8d09b0e4a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIlIPllno0hr",
        "outputId": "5076fc66-e2f4-44e4-99db-24a298ac59b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# MATRIX\n",
        "MATRIX = torch.tensor([[7, 8],\n",
        "                       [9, 10]])\n",
        "\n",
        "MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgNjBahNpG3v",
        "outputId": "fc42c967-c405-4cb1-fbfa-ce320513844a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "MATRIX.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwxCRX91pISw",
        "outputId": "7e67bf57-43b4-471f-80d6-5d334ba6327b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "MATRIX[0] # Gives us the tensor at 1st dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDTemLtepUaL",
        "outputId": "66ae94d4-2d3a-4837-8e35-a8fdb76a6429"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "MATRIX[1] # Gives us the tensor at 2nd dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98HtnIe_pZCO",
        "outputId": "1346987c-5398-4ab1-a251-3c358c8dc845"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "MATRIX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKilbMD7pcZP",
        "outputId": "7ab07165-e712-488d-b197-3d3c02cd06eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 7, 8],\n",
              "         [2, 7, 9]]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# TENSOR\n",
        "TENSOR = torch.tensor([[[1,2,3],\n",
        "                        [3,7,8],\n",
        "                        [2,7,9]]])\n",
        "TENSOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEgYqFIEp1G1",
        "outputId": "290ffa4a-3a5e-48e4-a8b4-1d4bd2d1e66f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "TENSOR.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVtKCJEHp266",
        "outputId": "f34b7bca-49af-4247-cdd3-45b30c20f3b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "TENSOR.shape  # Gives us number of elements in each dimension."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR[0][2][1].item()  # Indexing works how it's supposed to."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkMhupp5Bu-Q",
        "outputId": "70055f55-4efa-4644-f69d-cc0c9bd1fa36"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI6_9lIKp5Xi"
      },
      "source": [
        "### Notation:\n",
        "Matrices and Tensors are written in upper case. X, MATRIX etc.\n",
        "\n",
        "Scalars and Vectors are written lower case. a, b, names, etc.\n",
        "\n",
        "Not a compulsion though!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uruYWdKTvwF0"
      },
      "source": [
        "### Random Tensors\n",
        "\n",
        "Why random tensors?\n",
        "\n",
        "Random tensors are important because the neural networks start out with a tensor full of random values and then improve those values according to observations and patterns they see. They change those numbers to better represent that data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM3wMBdgvtoH",
        "outputId": "aed2a0b1-6ed1-49ba-d2e4-ddde9d432609"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0091, 0.4154, 0.9687, 0.0301],\n",
              "        [0.0066, 0.7570, 0.3154, 0.0561],\n",
              "        [0.4089, 0.6790, 0.2745, 0.5746]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Creating a random tensor of size (3,4) or shape(3,4).\n",
        "random_tensor = torch.rand(3,4)\n",
        "# The above line is the same as\n",
        "# random_tensor = torch.rand(size=(3,4))\n",
        "random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "aSpWUC0Owp11"
      },
      "outputs": [],
      "source": [
        "# Creating a random tensor with similar shape to an image tensor.\n",
        "# Let's suppose, the image is rgb and has resolution 224, 224.\n",
        "random_image_tensor = torch.rand(size=(224,224,3))  # 224 height, 224 width, 3 channels (R, G, B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YioRwmsyx0vR",
        "outputId": "f8229430-fac2-47e3-f0c7-56ea88115e46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "random_image_tensor.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLYzPRgox4ZT",
        "outputId": "91c246b0-dd40-4fb3-dd51-149a26f2895b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([224, 224, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "random_image_tensor.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rht4hLKsx6KS"
      },
      "source": [
        "### Zeros and Ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COmUgj6-ypQt",
        "outputId": "b32d7b6e-5589-4375-b0b9-0e94002c7ce3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Creating a tensor of all zeros\n",
        "zeros = torch.zeros(size=(3,4))\n",
        "zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWfZVygAy3vn",
        "outputId": "f9da1747-e39e-4d57-a56a-a4a6a7c984f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "zeros * random_tensor # This is element wise multiplication, so elements at corresponding positions are multiplied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaLf5BAFy_AC",
        "outputId": "29f5e227-c29a-4d5d-e871-f76ab8becae5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Creating a tensor of all ones\n",
        "ones = torch.ones(size=(3,4))\n",
        "ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwMZzIiEzJbb",
        "outputId": "51f259e7-1cc8-448a-c7c2-8715b269857b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "ones.dtype  # Tells us the default datatype of the object or variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoM_PtKHzOuL",
        "outputId": "be4cfd26-75b7-4cbf-ca7f-0a65dd6d42f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "random_tensor.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_308fJB3Ib9E"
      },
      "source": [
        "By default, any tensor created by PyTorch will be of the datatype float32 unless specified."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnvFlJJLzRQm"
      },
      "source": [
        "### Creating a range of Tensors and tensors-like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2f9RMvlozd8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fff376b0-fa64-42be-e9f2-257f53ba12f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Creating a 1D tensor (vector/array) with a specific number range.\n",
        "# torch.range(0, 10)  # This function will be deprecated. Instead use torch.arange()\n",
        "oneToTen = torch.arange(0,10)  # first index included, last index excluded. We can also add a step variable like in python.\n",
        "oneToTen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeroToHunnid = torch.arange(start=0, end=101, step=10)\n",
        "zeroToHunnid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg-PTUw3FHub",
        "outputId": "8ab5a339-0610-4879-dc8d-2a3b609fd998"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVhzBUhOzlFL",
        "outputId": "c3ffe126-8e2f-403d-81de-1bd36c17153b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Creating tensors like\n",
        "ten_zeros = torch.zeros_like(input=oneToTen)  # This creates a zero tensor with the same shape as input tensor.\n",
        "ten_zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqPAQUL80asj"
      },
      "source": [
        "### Tensor Datatypes\n",
        "\n",
        "**Note:-** Tensorflow datatypes are one of the big 3 errors that you'll run into in PyTorch and Deep Learning.\n",
        "1. Tensors not right datatype\n",
        "2. Tensors not right shape\n",
        "3. Tensors not on the right device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoBLVzaX0zHM",
        "outputId": "ed686f9e-a520-497e-e577-6792a73080c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Float 32 Tensor\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None,  # Specifies the datatype of the tensor.\n",
        "                               device=None, # We decide where the tensor is calculated. 'cuda' for gpu. 'cpu' for cpu.\n",
        "                               requires_grad=False) # Whether or not to track gradients with this tensor's operations.\n",
        "float_32_tensor.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzI7ay8r1a1Z"
      },
      "source": [
        "The above code outputs float32 eventhough we specified dtype as none because, in PyTorch, default datatype for any tensor is float32. We can change that though by explicitly specifying another datatype."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-4_nM061X8_",
        "outputId": "1747bdce-32c5-4ffb-c569-26f30f7f5701"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=torch.float16)\n",
        "\n",
        "#We could also do -\n",
        "# float_16_tensor = float_32_tensor.type(torch.float16)\n",
        "\n",
        "float_16_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Tir5XnDN1yIe"
      },
      "outputs": [],
      "source": [
        "ten = float_16_tensor * float_32_tensor # automatically casts float16 tensor to float32 tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXwvaRPX38pc",
        "outputId": "3cff633d-919c-4706-fdd1-b06a94686dac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "ten.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtDw3J6b4BXR"
      },
      "source": [
        "### Getting information from tensors (Tensor Attributes).\n",
        "1. Tensors not right datatype - to get datatype of tensor, we use `tensor.dtype`\n",
        "2. Tensors not right shape - to get shape of tensor, we use `tensor.shape`\n",
        "3. Tensors not on the right device - to get device of tensor, we use `tensor.device`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4adeCVIa5Qk2",
        "outputId": "e8fbfaa0-a269-4aa9-ca7a-af4fe4914195"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4437, 0.8951, 0.9300, 0.6931],\n",
              "        [0.9402, 0.4486, 0.1540, 0.7239],\n",
              "        [0.8697, 0.6839, 0.6802, 0.4107]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Create a random tensor\n",
        "some_tensor = torch.rand(3, 4)\n",
        "some_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOpE8gPa5kQA",
        "outputId": "8ce2fea2-3025-4fcb-cb55-1ec34a13d788"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "some_tensor.dtype # Datatype of tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHUE2YiC5nOD",
        "outputId": "3d698d46-f929-4d55-d5aa-4d17d85b313a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "some_tensor.device  # Device of tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qSQnbGB5oTF",
        "outputId": "062d7434-5545-4923-ed8e-3177f0435b06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "some_tensor.shape # Shape of tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgHtSfJC5pvH",
        "outputId": "0132a9ee-592b-4a40-df7b-a2419878926f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "some_tensor.size()  # This is the function that returns the shape too."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ptjqrTi6To3"
      },
      "source": [
        "### Manipulating Tensors (Tensor Operations)\n",
        "\n",
        "Tensor operations include -\n",
        "* Addition\n",
        "* Subtraction\n",
        "* Multiplication (Element-Wise)\n",
        "* Division\n",
        "* Matrix Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sdHJBiR7pe7",
        "outputId": "611abec0-920f-4838-8c89-64799fe3c7f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Creating a tensor and adding 10 to it.\n",
        "tensor = torch.tensor([1,2,3])\n",
        "tensor + 10 # Adds to each element"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHYJ0p4h8PqE",
        "outputId": "038c5140-7b10-49aa-e9fe-079cb512ba36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# Multiplay tensor by 10\n",
        "tensor * 10 # Multiplies each element by scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxZutRad8sfR",
        "outputId": "ae7afafe-0325-4e9e-8867-9abdbbba31ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Try out PyTorch in-built functions.\n",
        "torch.mul(tensor,10)  # Multiplies each element by scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjr_TWA_9FwL",
        "outputId": "8ca42bf8-e4f5-4080-e715-fdd245fa9c70"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "torch.add(tensor,10)  # Adds scalar to each element of tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ6J7Tum9RD9"
      },
      "source": [
        "### Matrix Multiplication\n",
        "Two main ways of performing multiplication in Neural Networks and Deep Learning.\n",
        "1. Element-wise Multiplication\n",
        "2. Matrix Multiplication (Dot Product)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYL7fqGSRWh0",
        "outputId": "440f2bf4-44b7-4c49-8f7f-3c469c683bac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equals: tensor([1, 4, 9])\n"
          ]
        }
      ],
      "source": [
        "# Elememt wise multiplication\n",
        "print(tensor, '*', tensor)\n",
        "print(f'Equals: {tensor * tensor}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVs7bgPER8vh",
        "outputId": "c3f25aa7-8609-466e-c601-330c1160a024"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Matrix Multiplication (Dot Product)\n",
        "torch.matmul(tensor, tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMnFUBw6Xhj2",
        "outputId": "d2ff4465-0c70-42af-d30a-1a324081993b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# Why did we get 14 - yaha pe we're multiplying 3x1 with 3x1 which isn't possible.\n",
        "# This is because, matmul returns dot product if both matrices are 1 dimensional.\n",
        "# So, it automatically takes transpose of one of the matrices and multiplies that with the other matrix.\n",
        "# So, solving it by hand,\n",
        "1*1 + 2*2 + 3*3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXjeeveeZNvZ",
        "outputId": "96909275-72fd-475e-9bf0-9f76067f07a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(14)\n",
            "CPU times: user 968 Âµs, sys: 0 ns, total: 968 Âµs\n",
            "Wall time: 3.78 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "  value += tensor[i] * tensor[i]\n",
        "print(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp41lzN6Z3Ab",
        "outputId": "4a602878-77f0-4f7b-8a55-fc3f5e7ecd6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 783 Âµs, sys: 0 ns, total: 783 Âµs\n",
            "Wall time: 2.38 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "%%time\n",
        "torch.matmul(tensor,tensor) # Much faster compared to above loop that does the same thing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1mkliLWZ-9E"
      },
      "source": [
        "### Rules for Matrix Multiplication -\n",
        "1. The **inner dimensions** must match.\n",
        "* `(3,2) X (3,2)` won't work\n",
        "* `(3,2) X (2,3)` will work\n",
        "* `(2,3) X (3,2)` will work\n",
        "\n",
        "2. The resulting tensor will have the shape of the outer dimensions.\n",
        "* `(3,2) X (2,2) = (3,2)`\n",
        "* `(5,8) X (8,4) = (5,4)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "5FbkZaOkbQcl",
        "outputId": "a204f0b3-7240-4e17-fbef-f5e42c6be52b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-5b5d35b4bf73>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This won't work, inner dimensions don't match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ],
      "source": [
        "torch.matmul(torch.rand(3,2), torch.rand(3,2))  # This won't work, inner dimensions don't match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc6I58ZbbXw5",
        "outputId": "bf73330e-3ee9-47e5-e299-d83a02ba639d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "torch.matmul(torch.rand(3,2), torch.rand(2,2)).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxStuaxYb7pp",
        "outputId": "e957bdcc-0f3c-4524-e2b8-10b9096c02d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "torch.matmul(torch.rand(5,8), torch.rand(8,4)).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FogSQZxlcBZ-"
      },
      "source": [
        "### One of the most common errors in deep learning is the shape error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "etRraz4kdROZ"
      },
      "outputs": [],
      "source": [
        "tensorA = torch.tensor([[1,2],\n",
        "                       [3,4],\n",
        "                       [5,6]])\n",
        "\n",
        "tensorB = torch.tensor([[7 ,8],\n",
        "                       [9 ,10],\n",
        "                       [11,12]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "OjrTgjMWdk0k",
        "outputId": "e12c4b73-17d2-4951-e89b-d86db777d00a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-b5499f09ca94>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Now if we try to multiply them, we get an error because inner dimensions don't match.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensorB\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# this is an alias function for torch.matmul(). Basically same function called using another name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ],
      "source": [
        "# Now if we try to multiply them, we get an error because inner dimensions don't match.\n",
        "torch.mm(tensorA, tensorB)  # this is an alias function for torch.matmul(). Basically same function called using another name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w8P4YOdd6R-",
        "outputId": "037e4aba-9a8b-4220-b2a5-144af7aea66c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  9, 11],\n",
              "        [ 8, 10, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# To fix this shape error, we take the transpose of the 2nd or the 1st matrix.\n",
        "tensorB_transpose = tensorB.T\n",
        "tensorB_transpose # Row became column, column became row. ^_^."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ay_TZAceCvQ",
        "outputId": "71ec8987-5518-4013-9015-d5f6ff5ea1ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 23,  29,  35],\n",
              "        [ 53,  67,  81],\n",
              "        [ 83, 105, 127]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "torch.matmul(tensorA, tensorB_transpose)  # Shape error fixed!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7Zk5s9QeygW"
      },
      "source": [
        "### Finding the min, max, mean, sum etc (Tensor Aggregation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa64VrElgMdF",
        "outputId": "afbfffa2-2a81-4dcc-e6c6-ec0525a99b4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# Creata a tensor\n",
        "x = torch.arange(0, 100, 10)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI0y3I_rgVMp",
        "outputId": "607361a2-585e-48af-989b-b90322cd5845"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0), tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# Finding the min\n",
        "torch.min(x), x.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIs8rctygb1X",
        "outputId": "e42ce36d-70a9-4551-f292-a263dc8aa009"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(90), tensor(90))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# Finding the max\n",
        "torch.max(x), x.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "e7rG5AkygfwF",
        "outputId": "66565964-611f-4aba-f8c4-c09d4a2408db"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-16cd50b728c4>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Finding the average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ahhahahahhaha tensor not right datatype error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
          ]
        }
      ],
      "source": [
        "# Finding the average\n",
        "torch.mean(x), x.mean() # ahhahahahhaha tensor not right datatype error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7zOiolWglCk",
        "outputId": "77583958-2e9b-42fb-90ee-1102b03f844b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "x.dtype # Our tensor is int64 (Long). But we need float or complex tensor in mean function."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor.type(dtype) function returns the type if dtype is not specified.\n",
        "\n",
        "If the dtype is specified, it returns a new tensor having the contents of the original tensor but with the specified datatype."
      ],
      "metadata": {
        "id": "Lwn1sIqSMM6e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCm22PgygtOY",
        "outputId": "ce89f0f2-97a8-4074-d285-eddf5454e9bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(45.), tensor(45.))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# Finding the average (again)\n",
        "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAUYoJoNMeJ8",
        "outputId": "ba7169ca-2fb1-4440-cc66-3c91f2a1be5f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBvVWnD4hREK",
        "outputId": "f7a8f3d4-4728-4526-d6ca-3f71f6946b7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(450), tensor(450))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "# Finding the sum\n",
        "torch.sum(x), x.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUQ2zP4MhzDE",
        "outputId": "ec5be006-c992-4183-9b03-53b6af36cfec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0), tensor(9))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# Position of min, max values in our tensors.\n",
        "torch.argmin(x), torch.argmax(x)\n",
        "# Could also do\n",
        "x.argmin(), x.argmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeEjzVr1h-tc"
      },
      "source": [
        "## Tensor Manipulation Part 2\n",
        "We perform the following manipulations on tensors -\n",
        "* reshape - changes the shape of the tensor to whatever we provide.\n",
        "* view - create another vector with different shape but that vector shares memory with the original vector.\n",
        "* stack - concatenating tensors along a single dimension.\n",
        "* squeeze - Removes the dimensions that have only 1 value in it (i.e dimensions of size 1).\n",
        "* unsqueeze - Adds single dimension at specified index in the tensor.\n",
        "* permute - Rearranges the dimensions of the tensor in specified way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPIkcZmdmMZx",
        "outputId": "8c1449d2-a31c-4faa-e020-325ba1dad890"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "import torch\n",
        "x = torch.arange(1, 11, 1)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BINUfzITmWuM",
        "outputId": "4b0df525-f821-440c-ece0-64c31f35dff7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5],\n",
              "        [ 6,  7,  8,  9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "x_reshaped1 = x.reshape(2,5)\n",
        "x_reshaped1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdvkBzDQmcMh",
        "outputId": "da9af55c-9ff9-4eb6-f017-33de469eb7ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2],\n",
              "        [ 3,  4],\n",
              "        [ 5,  6],\n",
              "        [ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "x_reshaped2 = x.reshape(5,2)\n",
        "x_reshaped2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "qmEg7Rmzmk_b",
        "outputId": "5968f183-33f5-47ed-bd73-0ea6aac212aa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-3fb2b129a9dd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If the number of elements in the original array does not match the dimensions of new array, we get an error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_reshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx_reshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[3, 3]' is invalid for input of size 10"
          ]
        }
      ],
      "source": [
        "# If the number of elements in the original array does not match the dimensions of new array, we get an error.\n",
        "x_reshape = x.reshape(3,3)\n",
        "x_reshape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCQnt1b_mvSv",
        "outputId": "709f3baa-2a03-409b-d876-c16d69ccd236"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5],\n",
              "        [ 6,  7,  8,  9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "# Changing the view.\n",
        "z = x.view(2,5)\n",
        "z # This z variable shares memory with our original tensor x. So, changing any value in z will change x also."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xC9Xg28m3uz",
        "outputId": "ffc03970-d2b0-498e-8583-e21de66781a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1,  2,  3,  4,  5],\n",
              "         [69,  7,  8,  9, 10]]),\n",
              " tensor([ 1,  2,  3,  4,  5, 69,  7,  8,  9, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "z[1,0] = 69\n",
        "z, x\n",
        "# As you can see, change reflected in x as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvGz9YRFnHGX",
        "outputId": "f88f0cff-354c-47c8-c77c-597871a3f895"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5, 69,  7,  8,  9, 10],\n",
              "        [ 1,  2,  3,  4,  5, 69,  7,  8,  9, 10],\n",
              "        [ 1,  2,  3,  4,  5, 69,  7,  8,  9, 10],\n",
              "        [ 1,  2,  3,  4,  5, 69,  7,  8,  9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "# Stacking tensors on top of each other.\n",
        "x_stacked = torch.stack((x, x, x, x), dim=0)\n",
        "# dim 0 means that the tensors are added horizontally in the same row one by one. Along the x axis.\n",
        "x_stacked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUhuFpNInk3b",
        "outputId": "1b0c35cd-577b-40e3-e262-774e7b32cdfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  1,  1,  1],\n",
              "        [ 2,  2,  2,  2],\n",
              "        [ 3,  3,  3,  3],\n",
              "        [ 4,  4,  4,  4],\n",
              "        [ 5,  5,  5,  5],\n",
              "        [69, 69, 69, 69],\n",
              "        [ 7,  7,  7,  7],\n",
              "        [ 8,  8,  8,  8],\n",
              "        [ 9,  9,  9,  9],\n",
              "        [10, 10, 10, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "x_stacked2 = torch.stack((x,x,x,x), dim=1)\n",
        "# dim 1 means stacked along the y axis. Basically same index wale elements are stacked together in a single array.\n",
        "x_stacked2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "verrYenWn0iC",
        "outputId": "170d76de-0d48-4773-91b3-c4e6966fb67d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2,  3,  4,  5, 69,  7,  8,  9, 10],\n",
              "        [ 1,  2,  3,  4,  5, 69,  7,  8,  9, 10],\n",
              "        [ 1,  2,  3,  4,  5, 69,  7,  8,  9, 10],\n",
              "        [ 1,  2,  3,  4,  5, 69,  7,  8,  9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "x_vertical = torch.vstack((x,x,x,x))\n",
        "x_vertical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxNp7K8FoIyC",
        "outputId": "057e9954-8653-49da-92b3-4e531876c236"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5, 69,  7,  8,  9, 10,  1,  2,  3,  4,  5, 69,  7,  8,\n",
              "         9, 10,  1,  2,  3,  4,  5, 69,  7,  8,  9, 10,  1,  2,  3,  4,  5, 69,\n",
              "         7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "x_horizontal = torch.hstack((x,x,x,x))\n",
        "x_horizontal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW5XBTovoQPG",
        "outputId": "0291a819-22cb-45d8-c23b-7bec6821e641"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[[0., 0.]],\n",
              "\n",
              "          [[0., 0.]]]],\n",
              "\n",
              "\n",
              "\n",
              "        [[[[0., 0.]],\n",
              "\n",
              "          [[0., 0.]]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "# Trying to use torch.squeeze()\n",
        "zeroTensor = torch.zeros(2,1,2,1,2)\n",
        "zeroTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_orDcgqWqNdF",
        "outputId": "f22da15e-f685-44b4-dc9c-8e74759f26b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "torch.squeeze(zeroTensor) # Basically the same as above but removed the dimensions where only 1 value was present."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X40x4hWrs5B-",
        "outputId": "51007294-70c2-4dd2-ae93-4ea108a3bd32"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 2, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "zeroTensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg9vvZxlrMYd",
        "outputId": "d326e287-ed5b-4340-b87a-b12a72d0ce20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "squeezedAlongDim = torch.squeeze(zeroTensor, dim=1)  # Squeezes the tensor only along the dimension at index 1 in shape tuple of the tensor.\n",
        "squeezedAlongDim.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dU3K-zotCYn",
        "outputId": "0a144396-0493-426d-89c7-26558d22b947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Squeezed Zero Tensor: \n",
            "tensor([[[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0.]],\n",
            "\n",
            "         [[0., 0.]]]])\n",
            "Squeezed Zero Tensor's Shape: torch.Size([2, 2, 1, 2])\n",
            "\n",
            "Unsqueezed Zero Tensor: \n",
            "tensor([[[[[0., 0.]],\n",
            "\n",
            "          [[0., 0.]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[0., 0.]],\n",
            "\n",
            "          [[0., 0.]]]]])\n",
            "Unsqueezed Zero Tensor's Shape: torch.Size([2, 1, 2, 1, 2])\n"
          ]
        }
      ],
      "source": [
        "# Trying to use torch.unsqueeze()\n",
        "# Adds a single dimension to the target tensor at the specified dim index. Basically the opposite of what squeeze does.\n",
        "\n",
        "print(f'Squeezed Zero Tensor: \\n{squeezedAlongDim}')\n",
        "print(f'Squeezed Zero Tensor\\'s Shape: {squeezedAlongDim.shape}')\n",
        "\n",
        "unsqueezed = torch.unsqueeze(squeezedAlongDim, dim=1)\n",
        "\n",
        "print()\n",
        "print(f'Unsqueezed Zero Tensor: \\n{unsqueezed}')\n",
        "print(f'Unsqueezed Zero Tensor\\'s Shape: {unsqueezed.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOuLHoG1uIf5"
      },
      "source": [
        "You can see, single dimension added at index 1 (because dim=1)\n",
        "\n",
        "### Permutation -\n",
        "\n",
        "It retuns a view of the original tensor with rearranged dimensions. It shares the memory with the original tensor so any changes to either of the tensors will change the other one too!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ub_c6XWt__N",
        "outputId": "12549101-d309-435f-84c6-9b833ffa6159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: torch.Size([2, 3, 5])\n",
            "Permuted shape: torch.Size([5, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "pTest = torch.randn(2, 3, 5)  # This has shape as (2, 3, 5)\n",
        "permuted_pTest = torch.permute(pTest, (2, 0, 1))\n",
        "# What we're doing is arranging dimensions such that dimension at index 2 in pTest ka shape tuple gets placed at index 0 in the new shape tuple.\n",
        "# Similarly, our 2nd dimension becomes index 0 of shape tuple of original tensor and, 3rd dimension becomes index 1 of shape tuple of original tensor.\n",
        "print(f'Original shape: {pTest.shape}')\n",
        "print(f'Permuted shape: {permuted_pTest.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlbDcfupwavw"
      },
      "source": [
        "### A better example would be rearranging image data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHS0v-EtwsBw",
        "outputId": "1701ab8b-7a90-4390-9342-fa643bf1492a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: torch.Size([28, 28, 3])\n",
            "Permuted shape: torch.Size([3, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "img_data = torch.rand(28,28,3)  # [height, width, color]\n",
        "\n",
        "# Permute(rearrange) the original dimensions.\n",
        "# We want to rearrange such that color becomes 1st dimension, then height and then width.\n",
        "img_data_permuted = img_data.permute(2,0,1)  # Shifts dimension 2->0, 0->1, 1->2.\n",
        "\n",
        "print(f'Original shape: {img_data.shape}')\n",
        "print(f'Permuted shape: {img_data_permuted.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1AVfoX4xim-",
        "outputId": "9c41797c-6819-4475-eb3c-acaf0aeef289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(420.)\n"
          ]
        }
      ],
      "source": [
        "img_data[0, 0, 0] = 420 # Permutation is just a view of the tensor. So changing original tensor changes permutation too.\n",
        "print(img_data_permuted[0, 0, 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y9P3lj2ye8b"
      },
      "source": [
        "## Indexing\n",
        "### Indexing with PyTorch is the similar to indexing with NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcGt1EVrzJLq",
        "outputId": "ed848734-d231-483b-e9f9-758cdd1783cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(1, 10).reshape(1,3,3)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-IwzLUTzVzn",
        "outputId": "041b7a41-1784-44a9-bd10-93fd79f9fbea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "# Let's index the middle bracket containing 4,5,6\n",
        "x[0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlWYvPFUzdWh",
        "outputId": "45ffbc43-4365-4f4a-d253-b044871cc1a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "# Can also use other notation.\n",
        "x[0][1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgbszNvUMBg2"
      },
      "source": [
        "## PyTorch Tensors and Numpy\n",
        "\n",
        "* Data in Numpy  -> Want in tensor --> `torch.from_numpy(ndarray)`\n",
        "* Data in tensor -> Want in Numpy  --> `torch.Tensor.numpy()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD4sVq6xM3JG",
        "outputId": "8b96d36f-6f75-4aae-c156-92d3d782001d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8Nvy_csNF7S",
        "outputId": "96ac6ff4-1349-48b0-d5af-aa3d26f47ae3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('float64'), torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "# Default datatype in pytorch is float32, whereas it's float64 in numpy.\n",
        "# When converting from numpy array to pytorch tensor, numpy's default datatype float64 is used unless specified\n",
        "array.dtype, tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KjXsZYKOCAS",
        "outputId": "6f64b5f6-ea82-4ddd-8214-df19f8889996"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "# Change the value of array, what will that do to tensor ?\n",
        "array = array + 1\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing the values in the numpy array won't affect the values in the created tensor. No memory is shared between the two."
      ],
      "metadata": {
        "id": "-kk6Edw7wiM3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cW4nVZgZQWDO",
        "outputId": "63215d31-cd0b-46ee-e540-2f4a4ba07bd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "# Tensor to Numpy Array\n",
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy()\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QKhpyZvROj7",
        "outputId": "0a514024-4858-461a-9683-647d5a5d756b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "# Change the tensor, what happens to numpy_tensor ?\n",
        "tensor = tensor + 1\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing the values in the tensor won't affect the values in the created numpy array. No memory is shared between the two."
      ],
      "metadata": {
        "id": "8iXFBBUWxAce"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17pmlWKNRoXl"
      },
      "source": [
        "## Reproducability (trying to take random out of the random)\n",
        "\n",
        "In short, how neural network learns:\n",
        "\n",
        "`start with random numbers -> tensor operations -> update random numbers to try to make them better representations of data -> repeat this...`\n",
        "\n",
        "To reduce the randomness in neural networks and PyTorch, we use the concept of random **seed**. To know what random seed is, watch the khan academy video on Cryptography."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOOm78EtRdOn",
        "outputId": "791ad8ed-2c77-48ab-9a26-8f98fbb4710a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4821, 0.4019, 0.6976, 0.1161],\n",
            "        [0.3645, 0.6144, 0.3966, 0.4642],\n",
            "        [0.7933, 0.3363, 0.6381, 0.8479]])\n",
            "tensor([[0.1538, 0.8150, 0.5810, 0.9378],\n",
            "        [0.2158, 0.0737, 0.3217, 0.1765],\n",
            "        [0.1242, 0.5517, 0.4853, 0.9709]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "tensorA = torch.rand(3, 4)\n",
        "tensorB = torch.rand(3, 4)\n",
        "\n",
        "print(tensorA)\n",
        "print(tensorB)\n",
        "print(tensorA == tensorB) # Prints the condition for each element of the tensor(WOW!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ2mh2fpSMKD",
        "outputId": "1913e042-2f7e-4cf2-8c08-9ef4ec6edbf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2713, 0.8702, 0.8820, 0.9400],\n",
            "        [0.2000, 0.4267, 0.3424, 0.8355],\n",
            "        [0.2013, 0.0134, 0.9623, 0.5154]])\n",
            "tensor([[0.2713, 0.8702, 0.8820, 0.9400],\n",
            "        [0.2000, 0.4267, 0.3424, 0.8355],\n",
            "        [0.2013, 0.0134, 0.9623, 0.5154]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ],
      "source": [
        "# Let's make a random number pattern but make it reproducible.\n",
        "import torch\n",
        "\n",
        "# Set the random seed.\n",
        "RANDOM_SEED = 295 # RIP\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "tensorC = torch.rand(3,4)\n",
        "\n",
        "# Need to set the random seed again in order to create the same numbers otherwise, it's gonna create random numbers further down the sequence.\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "tensorD = torch.rand(3,4)\n",
        "\n",
        "print(tensorC)\n",
        "print(tensorD)\n",
        "print(tensorC == tensorD) # Prints the condition for each element of the tensor(WOW!)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make a random number pattern but make it reproducible.\n",
        "import torch\n",
        "\n",
        "# Set the random seed.\n",
        "RANDOM_SEED = 295 # RIP\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "tensorC = torch.rand(3,4)\n",
        "tensorD = torch.rand(3,4)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "tensorE = torch.rand(3,4)\n",
        "tensorF = torch.rand(3,4)\n",
        "\n",
        "print(tensorD == tensorF) # Prints the condition for each element of the tensor(WOW!)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQOkxqZ1ywVw",
        "outputId": "a2abec0e-b465-4581-8130-f7ae6ae91c8f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you set the seed it starts generating random numbers and it goes on to reproduce random numbers in the same pattern. So, when you set the seed again, it generates the same numbers again. We can hence see that tensorD and tensorF have the same values."
      ],
      "metadata": {
        "id": "nUStveQizLas"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9McSicDDYycX"
      },
      "source": [
        "## Running tensors and PyTorch objects on GPUs (and making faster computations)\n",
        "\n",
        "### 1. Getting a GPU.\n",
        "Easiest way to do that is using colab. You can also access your nvidia gpu if you have one. I have a mac m1 so smh."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T83BfppwcJ78",
        "outputId": "7c3fb3a4-1325-4094-d1ad-aeec8e57fd33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Aug 24 18:53:02 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWPBQU6tclyO"
      },
      "source": [
        "## Running Torch tensors on GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_8oK_0tcK_p",
        "outputId": "d23c2098-fd8a-4330-dea0-0f860e54573f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available() # Returns if GPU is available to work on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B9CFgltAcyh_",
        "outputId": "7d733724-e8b6-4668-fcda-2d73b4e1b11d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "# We create a device variable to store what kind of device we're working on\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' # This is good practice to write device agnostic code.\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5hxdu--dKxi",
        "outputId": "dd67bea7-a97b-46ea-c143-d815b2414cae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "# Counting the number of GPUs available for us.\n",
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdMfMJEvd0Q0"
      },
      "source": [
        "## Putting tensors (and models) on GPU.\n",
        "\n",
        "To change the device of the tensor you're working with, you can call the `to(device)` function.\n",
        "\n",
        "Putting a tensor on GPU using `to(device)` (e.g. `some_tensor.to(device)`) returns a copy of that tensor, e.g. the same tensor will be on CPU and GPU. To overwrite tensors, reassign them:\n",
        "some_tensor = some_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rH-LVZYedAb",
        "outputId": "4d008e43-9d1e-4a7c-e8f3-8f1b46e9c79f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "# Creating a Tensor on CPU.\n",
        "tensor = torch.tensor([1,2,3])\n",
        "tensor.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv1AqEVyekHX",
        "outputId": "a35be39e-7fcc-4efa-e2be-67e7ab1d08a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "# tensorGPU = torch.tensor([1,2,3], device='cuda')\n",
        "tensorGPU = tensor.to(device) # Creates a copy of our tensor in upper code block and puts it on the gpu.\n",
        "tensorGPU.device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svTUUbZ_ep5q"
      },
      "source": [
        "## Moving tensors back to CPU.\n",
        "\n",
        "You would do this if you want to interact with numpy arrays because numpy does not utilize GPUs.\n",
        "So, let's try using the `torch.Tensor.numpy()` method on our tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "MzKMMQXBfplo",
        "outputId": "b6f5d5bd-20a4-49b7-f958-78f04ed5a2cc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-52b4dc6094f3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensorGPU\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This throws an error saying that we can't convert a GPU tensor to numpy array.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# We could also call tensorGPU.numpy() and it would be the same as the above line of code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ],
      "source": [
        "torch.Tensor.numpy(tensorGPU) # This throws an error saying that we can't convert a GPU tensor to numpy array.\n",
        "# We could also call tensorGPU.numpy() and it would be the same as the above line of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaC28x3PfuKQ",
        "outputId": "97136a19-5b18-4733-abd1-35975f016320"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "# To fix this issue, we use torch.Tensor.cpu()\n",
        "# This copies the Tensor to CPU memory so we can change it to arrays and shit.\n",
        "tensorCPU = torch.Tensor.cpu(tensorGPU).numpy()\n",
        "tensorCPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC50jLncgTVm"
      },
      "source": [
        "## END OF THE FIRST UNIT. NOW WE MOVE ON TO CREATE A MODEL! EXCITING STUFF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uycSzwujigdO"
      },
      "source": [
        "## Exercise Solutions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-h7j_5eiitU",
        "outputId": "1eda8123-69c4-484c-970c-92e5884fb5ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4859, 0.3302, 0.3119, 0.0943, 0.6769, 0.2081, 0.9878],\n",
              "        [0.7300, 0.6370, 0.9109, 0.2260, 0.2113, 0.0396, 0.4422],\n",
              "        [0.3240, 0.2898, 0.7094, 0.8410, 0.8604, 0.0363, 0.6487],\n",
              "        [0.1295, 0.8803, 0.2609, 0.6288, 0.3626, 0.4674, 0.8558],\n",
              "        [0.5846, 0.0383, 0.0263, 0.3287, 0.4921, 0.5110, 0.6804],\n",
              "        [0.1035, 0.0851, 0.5707, 0.3973, 0.5902, 0.1479, 0.1638],\n",
              "        [0.9017, 0.0846, 0.7207, 0.5784, 0.8937, 0.7744, 0.7269]])"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "import torch\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "tensor = torch.rand((7,7))\n",
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RULZXsiGiqsE",
        "outputId": "7130a2e0-b7ae-4fed-8f3e-79076cca4a12"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.7849],\n",
              "         [1.7541],\n",
              "         [1.9744],\n",
              "         [2.1128],\n",
              "         [1.7936],\n",
              "         [1.1029],\n",
              "         [2.9548]]),\n",
              " torch.Size([7, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "tensor2 = torch.rand(1,7)\n",
        "multiplied = torch.matmul(tensor, tensor2.T)\n",
        "multiplied, multiplied.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 0\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "A = torch.rand((7,7))\n",
        "B = torch.rand((1,7))\n",
        "C = torch.mm(A, B.T)\n",
        "C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNgbort23jYI",
        "outputId": "2c90e1b2-45a7-4c98-8976-60fff091a45c"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.8542],\n",
              "        [1.9611],\n",
              "        [2.2884],\n",
              "        [3.0481],\n",
              "        [1.7067],\n",
              "        [2.5290],\n",
              "        [1.7989]])"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bwJaws7eZ-R",
        "outputId": "e4ccccdc-26ae-4690-8e49-69fc772edcc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.5932, 0.1123, 0.1535],\n",
              "         [0.2417, 0.7262, 0.7011]], device='cuda:0'),\n",
              " tensor([[0.2038, 0.6511, 0.7745],\n",
              "         [0.4369, 0.5191, 0.6159]], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "torch.cuda.manual_seed(1234)\n",
        "t1 = torch.rand((2, 3)).to(device)\n",
        "t2 = torch.rand((2, 3)).to(device)\n",
        "t1, t2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t93KFfVhHHQ",
        "outputId": "33bb58ec-ee90-43a8-ef50-df8d46c904ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3129, 0.4120],\n",
              "        [1.0651, 0.9143]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "mul = torch.matmul(t1, t2.T)\n",
        "mul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFG4XgJGjtBg",
        "outputId": "f0d13204-0b4f-49a0-e319-803b08bc4cec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1.0651, device='cuda:0'), tensor(0.3129, device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ],
      "source": [
        "maxval = mul.max()\n",
        "minval = mul.min()\n",
        "\n",
        "maxval, minval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "YvCGLrf_j7sv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df6db6c6-b19b-4054-9f39-8c9e6982f652"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(2, device='cuda:0'), tensor(0, device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "maxIndex = mul.argmax()\n",
        "minIndex = mul.argmin()\n",
        "\n",
        "maxIndex, minIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipmY8o3tkQuH",
        "outputId": "fc20ac85-6423-4faf-c1a8-ef605d21e642"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[[0.8102, 0.9801, 0.1147, 0.3168, 0.6965, 0.9143, 0.9351, 0.9412,\n",
              "            0.5995, 0.0652]]]], device='cuda:0'),\n",
              " tensor([0.8102, 0.9801, 0.1147, 0.3168, 0.6965, 0.9143, 0.9351, 0.9412, 0.5995,\n",
              "         0.0652], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ],
      "source": [
        "torch.cuda.manual_seed(1234)\n",
        "TENSOR = torch.rand((1,1,1,10)).to(device)\n",
        "changedTensor = TENSOR.squeeze()\n",
        "TENSOR, changedTensor"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}