{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Custom Datasets\n",
        "Reference book --> https://www.learnpytorch.io/04_pytorch_custom_datasets/\n",
        "\n",
        "We've used the datasets which PyTorch provides, but how to use our own data for training and testing? Let's find out\n",
        "\n",
        "## Domain Libraries\n",
        "Depending on what kind problem we're working on, text, audio, vision, recommendation, we'll look into PyTorch domain libraries for existing data loading functions and customizable data loading functions.\n",
        "\n",
        "We're working on a vision problem, so we'll be checking out the custom data loading functions for `torchvision`."
      ],
      "metadata": {
        "id": "KMwKKzwxUfUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Importing PyTorch and setting up device agnostic code\n"
      ],
      "metadata": {
        "id": "GkHCfEJ5VuSl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QoYLlX2eSPLE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a85e16b8-0bbc-4f2a-c22a-91b9dde53fb4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyD1P3HqUPIB",
        "outputId": "efe47735-5421-4f44-efc4-f4e742ead580"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xihzwr1gWLr6",
        "outputId": "e2394e6b-44a5-4148-f3d6-80108a06f2f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get Data\n",
        "Our dataset is the subset of Food101 dataset.\n",
        "\n",
        "Food101 has 101 different classes of food and 1000 images per class. (750 testing, 250 training).\n",
        "\n",
        "Our dataset has only 3 classes of images and 10% of the data (75 testing images, 25 training images). We're doing this to speed up our experiments as larger dataset would take too long for computation."
      ],
      "metadata": {
        "id": "y2ldGChV6Fxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to a data folder.\n",
        "data_path = Path('data/')\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download and unzip\n",
        "if image_path.is_dir():\n",
        "  print(f'{image_path} already exists... Skipping Download.')\n",
        "else:\n",
        "  print(f'{image_path} does not exist. Creating directory...')\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # Download pizza, steak, sushi data\n",
        "  with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "    print(\"Downloading pizza, steak, sushi data...\")\n",
        "    f.write(request.content)\n",
        "\n",
        "  # Unzip pizza, steak, sushi data\n",
        "  with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping pizza, steak, sushi data...\")\n",
        "    zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "1nmk2FRUWQgQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb3ca10-c47d-477c-bf60-5df6ac1d6220"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/pizza_steak_sushi does not exist. Creating directory...\n",
            "Downloading pizza, steak, sushi data...\n",
            "Unzipping pizza, steak, sushi data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9OUUsm1Fg2Zs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}