{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Digit Classification from MNIST Dataset.\n",
        "\n",
        "Creating a feed forward neural network for digit classification from the famous MNIST dataset. Also adding GPU support."
      ],
      "metadata": {
        "id": "P_XZh_6R74MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "j5DkWXK38H46"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device config\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "\n",
        "# hyper parameters\n",
        "input_size = 784  # mnist has 28x28 images, which after flattening becomes 784\n",
        "hidden_size = 100\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n"
      ],
      "metadata": {
        "id": "lus6MHKg8YR9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing MNIST\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True,\n",
        "                                           download=True, transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False,\n",
        "                                           download=True, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "UqG-p2Jf9EM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = iter(train_loader)\n",
        "samples, labels = next(examples)\n",
        "print(samples.shape, labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVWxBcpN97Td",
        "outputId": "b06d51cf-11d8-4dad-b93a-e06e2ae3b01b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see from the shape that our samples has a shape of 100x1x28x28, 100 being the batch size. We also see that our labels are in a 1-D array.\n",
        "\n",
        "We may need to first flatten our samples into an array of 100x784."
      ],
      "metadata": {
        "id": "7LIj06by-Pqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(6):\n",
        "  plt.subplot(2, 3, i+1)  # creating a grid with 2 rows and 3 cols\n",
        "  plt.imshow(samples[i][0], cmap='gray')  # plotting images with color map = gray\n",
        "  plt.show  # display"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "7OaqHadq-MvW",
        "outputId": "653e9b3f-3acf-4181-ea97-82375ab3908b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    return out\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes)"
      ],
      "metadata": {
        "id": "s_kg7tir_Umy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're not using softmax here because we'll be using cross entropy as our loss and PyTorch's cross entropy applies softmax to it's inputs, so doing that manually would be to apply softmax twice, which makes training slow."
      ],
      "metadata": {
        "id": "NPI9EjwHAlke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "HVGbqIykBtpE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward pass\n",
        "    optimizer.zero_grad() # setting the gradients to zero\n",
        "    loss.backward() # backpropagation\n",
        "    optimizer.step()  # optimizing our parameters\n",
        "\n",
        "    if (i+1)%100 == 0:\n",
        "      print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iezfwTNwB7oa",
        "outputId": "cac7fbfb-bc54-4e2b-c787-94af9b329b58"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 / 2, step 100/600, loss = 0.6006\n",
            "epoch 1 / 2, step 200/600, loss = 0.3164\n",
            "epoch 1 / 2, step 300/600, loss = 0.2374\n",
            "epoch 1 / 2, step 400/600, loss = 0.2946\n",
            "epoch 1 / 2, step 500/600, loss = 0.2658\n",
            "epoch 1 / 2, step 600/600, loss = 0.2804\n",
            "epoch 2 / 2, step 100/600, loss = 0.2954\n",
            "epoch 2 / 2, step 200/600, loss = 0.1722\n",
            "epoch 2 / 2, step 300/600, loss = 0.1573\n",
            "epoch 2 / 2, step 400/600, loss = 0.3093\n",
            "epoch 2 / 2, step 500/600, loss = 0.2837\n",
            "epoch 2 / 2, step 600/600, loss = 0.1303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing -\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "\n",
        "  for images, labels in test_loader:\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    # returns value, index. We only need index i.e the class label\n",
        "    _, predictions = torch.max(outputs, 1)  # returns the index having the highest value.\n",
        "    n_samples += labels.shape[0]  # Gives us number of samples in current batch (should be 100)\n",
        "    n_correct += (predictions == labels).sum().item() # adding 1 for every correct prediction.\n",
        "\n",
        "  acc = 100 * n_correct / n_samples\n",
        "  print(f'accuracy = {acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HZgTZJNDGWU",
        "outputId": "d745da67-ccce-4b75-b4d2-664a8c1322a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 95.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VXivBB8UEZ_K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}