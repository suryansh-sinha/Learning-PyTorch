{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and Dataloader in PyTorch\n",
        "\n",
        "Some important terminologies -\n",
        "- 1 epoch = 1 forward and backward pass on all data samples\n",
        "- batch_size = number of training samples in one forward and backward pass\n",
        "- number of iterations = number of passes, each pass using [batch_size] number of samples\n",
        "- example: We have 100 samples, with batch size = 20, then number of iterations = 5 (100/20) for 1 epoch."
      ],
      "metadata": {
        "id": "Qo8XrPTWTl7n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dltwvKWzSuCY",
        "outputId": "91833201-eb7f-430b-fff5-957b36ed85cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03]) tensor([1.])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# creating a custom class for our dataset, which inherits from Dataset.\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "    # this function is used for data loading\n",
        "    def __init__(self):\n",
        "      # data loading\n",
        "      xy = np.loadtxt('./wine.csv', delimiter=',', dtype=np.float32, skiprows=1)\n",
        "      self.x = torch.from_numpy(xy[:, 1:])  # the first column is the output label\n",
        "      self.y = torch.from_numpy(xy[:, [0]]) # n_samples, 1\n",
        "      self.n_samples = xy.shape[0]\n",
        "\n",
        "    # this function allows indexing in our dataset\n",
        "    def __getitem__(self, index):\n",
        "      return self.x[index], self.y[index] # the function returns a tuple.\n",
        "\n",
        "    # this allows us to call len on our dataset.\n",
        "    def __len__(self):\n",
        "      return self.n_samples\n",
        "\n",
        "dataset = WineDataset()\n",
        "# First sample of our dataset. # This should return a tuple.\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader Class\n",
        "\n",
        "At the heart of PyTorch data loading utility is the ```torch.utils.data.DataLoader``` class. It represents a Python iterable over a dataset.\n",
        "\n",
        "For example, if you've got a Dataset of 1000 images, you can iterate certain attributes in the order that they've been stored in the Dataset and nothing else by itself. In the other hand, a DataLoader that wraps that Dataset allows you to iterate the data in batches, shuffle the data, apply functions, sample data, etc.\n",
        "\n",
        "A dataloader only iterates a dataset, it does not modify it's contents. To be precise, for example, it doesn't shuffle the dataset contents, but it can iterate the contents of a dataset in a random order\n",
        "\n",
        "For an object to be iterable, we must define the ```__iter__()``` method inside it's class. Since this is already defined in the DataLoader class, we can call both, the ```enumerate()``` and the ```iter()``` methods on the dataloader."
      ],
      "metadata": {
        "id": "OQ9TxdgPeI0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle=True shuffles the data, num_workers=2 uses multiple subprocesses, making loading faster.\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)\n"
      ],
      "metadata": {
        "id": "FUAbplu3X6Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ```iter()``` function looks for the ```__iter__()``` function in the object's class and calls for it behind the scenes. What the iter function does is returns an iterator."
      ],
      "metadata": {
        "id": "9f7K52mfmlud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can convert the dataloader object to an iterator.\n",
        "dataiter = iter(dataloader)\n",
        "# The next function gives the first value from the dataset. \n",
        "# Everytime it's called, it gives us the next value from the iterator (i.e our dataset)\n",
        "data = next(dataiter)\n",
        "features, labels = data\n",
        "print(features, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R41I-NmEYZ9V",
        "outputId": "7a5ad602-a1f6-473d-9a52-48fd7f28364a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.2330e+01, 1.1000e+00, 2.2800e+00, 1.6000e+01, 1.0100e+02, 2.0500e+00,\n",
            "         1.0900e+00, 6.3000e-01, 4.1000e-01, 3.2700e+00, 1.2500e+00, 1.6700e+00,\n",
            "         6.8000e+02],\n",
            "        [1.3320e+01, 3.2400e+00, 2.3800e+00, 2.1500e+01, 9.2000e+01, 1.9300e+00,\n",
            "         7.6000e-01, 4.5000e-01, 1.2500e+00, 8.4200e+00, 5.5000e-01, 1.6200e+00,\n",
            "         6.5000e+02],\n",
            "        [1.3170e+01, 5.1900e+00, 2.3200e+00, 2.2000e+01, 9.3000e+01, 1.7400e+00,\n",
            "         6.3000e-01, 6.1000e-01, 1.5500e+00, 7.9000e+00, 6.0000e-01, 1.4800e+00,\n",
            "         7.2500e+02],\n",
            "        [1.3940e+01, 1.7300e+00, 2.2700e+00, 1.7400e+01, 1.0800e+02, 2.8800e+00,\n",
            "         3.5400e+00, 3.2000e-01, 2.0800e+00, 8.9000e+00, 1.1200e+00, 3.1000e+00,\n",
            "         1.2600e+03]]) tensor([[2.],\n",
            "        [3.],\n",
            "        [3.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are getting this output because we set our batch_size to four. So, 1 batch from our dataset has 4 samples in it. The shape of the data is (4, 13).\n",
        "\n",
        "Now creating a dummy training loop."
      ],
      "metadata": {
        "id": "g04f9SLua6u3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iters = math.ceil(total_samples / 4)   # divided by batch size.\n",
        "print(total_samples, n_iters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NiyKPO6bNRP",
        "outputId": "674fe7f5-5781-4d4f-9635-4fb844912780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ```enumerate()``` function returns the index of the data along with the data for an iterable. So, what we are doing is already unpacking the data into inputs and labels and we are storing our index in i.\n",
        "\n",
        "The ```enumerate()``` is a constructor method returns an object of the enumerate class for the given iterable, sequence, iterator, or object that supports iteration. The returned enumerate object contains tuples for each item in the iterable that includes an index and the values obtained from iterating over iterable.\n",
        "\n",
        "Some documentation for the enumerate function - https://www.tutorialsteacher.com/python/enumerate-method"
      ],
      "metadata": {
        "id": "qI1sbYeacB8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  # i, (inputs, labels) works because of tuple unpacking in python3.\n",
        "  for i, (inputs, labels) in enumerate(dataloader):\n",
        "    # forward, backward, update\n",
        "    # now printing some info.\n",
        "    if (i+1)%5 == 0:\n",
        "      print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iters}, inputs {inputs.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBDS8abnb1DB",
        "outputId": "8455168b-2e92-4773-b016-84c578d77482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/2, step 5/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 10/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 15/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 20/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 25/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 30/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 35/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 40/45, inputs torch.Size([4, 13])\n",
            "epoch 1/2, step 45/45, inputs torch.Size([2, 13])\n",
            "epoch 2/2, step 5/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 10/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 15/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 20/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 25/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 30/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 35/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 40/45, inputs torch.Size([4, 13])\n",
            "epoch 2/2, step 45/45, inputs torch.Size([2, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch already has some built in datasets. We will use them later in some projects."
      ],
      "metadata": {
        "id": "Sb5TCl14dSLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torchvision.datasets.MNIST() is the famous MNIST dataset."
      ],
      "metadata": {
        "id": "o825DRicc0FK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}